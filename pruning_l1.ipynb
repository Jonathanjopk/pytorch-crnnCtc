{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from src.model import CRNN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "!where python3"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/bin/python3\n",
      "/usr/bin/python3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "model = CRNN(img_channel=32, img_height=128, img_width=128, num_class=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "model.cnn"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu0): ReLU(inplace=True)\n",
       "  (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (pooling2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu4): ReLU(inplace=True)\n",
       "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu5): ReLU(inplace=True)\n",
       "  (pooling3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu6): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## compute_thres"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "global pruning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# 剪枝比率\n",
    "pruning_rate = 0.5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "\"\"\"計算global threshold\"\"\"\n",
    "# 計算總共多少 channels\n",
    "total = 0\n",
    "cfg = [32]\n",
    "for m in model.cnn.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        total += m.weight.data.shape[0]\n",
    "        cfg.append(m.weight.data.shape[0])\n",
    "        # weight_copy = m.weight.data.abs().clone()\n",
    "        # weight_copy = weight_copy.cpu().numpy()\n",
    "        # total += weight_copy\n",
    "\n",
    "# 所有 weights 值 取絕對值存進 bn\n",
    "bn = torch.zeros(total) # 1*n維\n",
    "weight_list = []\n",
    "index = 0\n",
    "for k, m in enumerate(model.cnn.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(k, m.weight.data.shape[0])\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        weight_copy = weight_copy.cpu().numpy()\n",
    "\n",
    "        # num_keep = int(out_channels * (1 - pruning_rate)) # 要留下多少比例 (1 - pruning rate)\n",
    "        # print('num_keep:', num_keep)\n",
    "        L1_norm = np.sum(weight_copy, axis=(1, 2, 3)) # 算L1 全部加總\n",
    "        '''\n",
    "        [8.548319  8.584734  7.830537  8.143877  9.192205  8.561562  8.281859\n",
    "        8.481453  8.994378  8.91869   8.544003  8.693865  8.306074  8.96825 ...]\n",
    "        看這層有幾個channels就有幾個L1加總\n",
    "        '''\n",
    "        # if k == 16:\n",
    "        #     print(m.weight.data.shape[0])\n",
    "        #     print(L1_norm)\n",
    "        #     break\n",
    "        weight_list += list(L1_norm)\n",
    "sort_list = sorted(weight_list)\n",
    "thre_index = int(total * pruning_rate) # scale sparse rate 0.5 剪枝比例\n",
    "thre = sort_list[thre_index] if thre_index != 0 else 0 # 取第 thre_index 個值當作 threshold，如果 thre_index=0 代表全留，不能取第 0 個要直接改 0\n",
    "\n",
    "# 之後 weight 會跟 thre 這個數字比大小，產生一個 0, 1 的 tensor，大於 thre 的留下(小於 thre 的就不會被存進 newmodel)\n",
    "print('Global threshold: {}'.format(thre))\n",
    "print('Total channels: {}'.format(total))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 64\n",
      "5 128\n",
      "9 256\n",
      "12 256\n",
      "16 512\n",
      "19 512\n",
      "23 512\n",
      "Global threshold: 23.763320922851562\n",
      "Total channels: 2240\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "\"\"\"記錄誰該留下誰該剪掉\"\"\"\n",
    "pruned = 0\n",
    "cfg_new = [32] # remaining channel\n",
    "cfg_mask = [torch.ones(32)] # 記錄每層 channels，以 0,1 表示剪枝，假設 channels=3, cfg_mask=[0,1,1]\n",
    "for k, m in enumerate(model.cnn.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        thre_ = 0 if k in pruning_cfg['cnn']['skip'] else thre # skip 的 layer thre=0\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        weight_copy = weight_copy.cpu().numpy()\n",
    "        L1_norm = np.sum(weight_copy, axis=(1, 2, 3)) # 算L1 全部加總\n",
    "        L1_tensor = torch.from_numpy(L1_norm)\n",
    "        # print(thre)\n",
    "        # print(L1_tensor)\n",
    "        mask = L1_tensor.gt(thre_).float() # 比大小，大的標記 1 & 小的標記 0，存進 mask\n",
    "        # print(mask)\n",
    "        # if k ==2:\n",
    "        #     break\n",
    "        cfg_new.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.clone())\n",
    "\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask) # 計算pruning ratio\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "pruned_ratio = pruned / total\n",
    "print('-------------------------------------------------------------------------')\n",
    "print('channels pruned / channels total: {} / {}'.format(pruned, total))\n",
    "print('pruned ratio: {}'.format(pruned_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layer index: 1 \t total channel: 64 \t remaining channel: 0\n",
      "layer index: 5 \t total channel: 128 \t remaining channel: 0\n",
      "layer index: 9 \t total channel: 256 \t remaining channel: 0\n",
      "layer index: 12 \t total channel: 256 \t remaining channel: 202\n",
      "layer index: 16 \t total channel: 512 \t remaining channel: 405\n",
      "layer index: 19 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 23 \t total channel: 512 \t remaining channel: 0\n",
      "-------------------------------------------------------------------------\n",
      "channels pruned / channels total: 1121.0 / 2240\n",
      "pruned ratio: 0.5004464387893677\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "print(cfg)\n",
    "print(cfg_new)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[32, 64, 128, 256, 256, 512, 512, 512]\n",
      "[32, 0, 0, 0, 202, 405, 512, 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set param"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# cfg\n",
    "'''\n",
    "model: 各架構位置\n",
    "skip: 不剪枝的層數\n",
    "cfg: 剪枝後剩餘的 channel 數量\n",
    "cfg_mask: 剪枝後剩餘 channel 的位置\n",
    "cat_layer: 有 concat 的層數\n",
    "'''\n",
    "pruning_cfg = {\n",
    "    'cnn':{\n",
    "        'model': model.cnn,\n",
    "        'skip': [],\n",
    "        'cfg': [],\n",
    "        'cfg_mask': [],\n",
    "        'cat_layer': []\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cfg = [64, 128, 256, 256, 512, 512, 512]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "cfg_mask = []\n",
    "cfg_new = [32]\n",
    "# layer_id = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        out_channels = m.weight.data.shape[0]\n",
    "\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        weight_copy = weight_copy.cpu().numpy()\n",
    "        num_keep = int(out_channels * (1 - pruning_rate)) # 要留下多少比例 (1 - pruning rate)\n",
    "        # print('num_keep:', num_keep)\n",
    "        L1_norm = np.sum(weight_copy, axis=(1, 2, 3)) # 算L1 全部加總\n",
    "        arg_max = np.argsort(L1_norm)\n",
    "        # x中的元素從小到大排列，提取其對應的index(索引)，然後輸出到y\n",
    "        # x=np.array([1,4,3,-1,6,9])\n",
    "        # y=array([3,0,2,1,4,5])\n",
    "\n",
    "        # arg_max_rev = arg_max[::-1][:cfg[layer_id]]\n",
    "        #[::-1]小排到大，[:num_keep]取要留下的\n",
    "        arg_max_rev = arg_max[::-1][:num_keep] # 留下哪幾個filters\n",
    "        # print('arg_max_rev:', len(arg_max_rev))\n",
    "        # print(arg_max_rev)\n",
    "\n",
    "        # assert arg_max_rev.size == cfg[layer_id], \"size of arg_max_rev not correct\"\n",
    "        mask = torch.zeros(out_channels) # 一個空的 裡面都存0的matrix， 1*out_channels維\n",
    "        mask[arg_max_rev.tolist()] = 1 # 把要留下的人給1\n",
    "        cfg_mask.append(mask) # [tensor(一堆0, 1), tensor(一堆0, 1)]\n",
    "        cfg_new.append(num_keep)\n",
    "        print(f'original channels:{out_channels}, num_keep:{num_keep}')\n",
    "        # print(cfg_mask)\n",
    "        \n",
    "        # layer_id += 1\n",
    "    # elif isinstance(m, nn.MaxPool2d):\n",
    "    #     layer_id += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "original channels:64, num_keep:32\n",
      "original channels:128, num_keep:64\n",
      "original channels:256, num_keep:128\n",
      "original channels:256, num_keep:128\n",
      "original channels:512, num_keep:256\n",
      "original channels:512, num_keep:256\n",
      "original channels:512, num_keep:256\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## save weights to new model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "# cfg\n",
    "'''\n",
    "model: 各架構位置\n",
    "skip: 不剪枝的層數\n",
    "cfg: 剪枝後剩餘的 channel 數量\n",
    "cfg_mask: 剪枝後剩餘 channel 的位置\n",
    "cat_layer: 有 concat 的層數\n",
    "'''\n",
    "pruning_cfg = {\n",
    "    'cnn':{\n",
    "        'model': model.cnn,\n",
    "        'skip': [],\n",
    "        'cfg': cfg_new,\n",
    "        'cfg_mask': cfg_mask,\n",
    "        'cat_layer': []\n",
    "    }\n",
    "}\n",
    "print(pruning_cfg['cnn']['cfg'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[32, 0, 0, 0, 202, 405, 512, 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 用新的 cfg 定義新模型架構\n",
    "newmodel = CRNN(img_channel=1, img_height=32, img_width=100, num_class=42, pruning_cfg=pruning_cfg['cnn']['cfg'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "start_mask = torch.ones(32)\n",
    "layer_id_in_cfg = 0\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "for [m0, m1] in zip(model.modules(), newmodel.modules()):\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        print('batch:', layer_id_in_cfg)\n",
    "        print('======================')\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1,(1,))\n",
    "        m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "        m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "        m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "        m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "        layer_id_in_cfg += 1\n",
    "        start_mask = end_mask\n",
    "        if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "            end_mask = cfg_mask[layer_id_in_cfg]\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        print('conv:', layer_id_in_cfg)\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "        if idx0.size == 1:\n",
    "            idx0 = np.resize(idx0, (1,))\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1, (1,))\n",
    "        w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "        w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "        m1.weight.data = w1.clone()\n",
    "        # print(m1.weight.data.shape)\n",
    "        # break\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        if layer_id_in_cfg == len(cfg_mask):\n",
    "            print('Linear:', layer_id_in_cfg)\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[-1].cpu().numpy())))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            continue\n",
    "        m1.weight.data = m0.weight.data.clone()\n",
    "        m1.bias.data = m0.bias.data.clone()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv: 0\n",
      "In shape: 32, Out shape 32.\n",
      "batch: 0\n",
      "======================\n",
      "conv: 1\n",
      "In shape: 32, Out shape 64.\n",
      "batch: 1\n",
      "======================\n",
      "conv: 2\n",
      "In shape: 64, Out shape 128.\n",
      "batch: 2\n",
      "======================\n",
      "conv: 3\n",
      "In shape: 128, Out shape 128.\n",
      "batch: 3\n",
      "======================\n",
      "conv: 4\n",
      "In shape: 128, Out shape 256.\n",
      "batch: 4\n",
      "======================\n",
      "conv: 5\n",
      "In shape: 256, Out shape 256.\n",
      "batch: 5\n",
      "======================\n",
      "conv: 6\n",
      "In shape: 256, Out shape 256.\n",
      "batch: 6\n",
      "======================\n",
      "Linear: 7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# 新的 model\n",
    "# torch.size() 順序是 output channel,  input channel, kernel size\n",
    "for i in newmodel.cnn.state_dict():\n",
    "    if ('conv' in i) and ('weight' in i):\n",
    "        print((\"================= {} =================\").format(i.split('.')[0]))\n",
    "        print('Conv shape: {}'.format(newmodel.cnn.state_dict()[i].shape))\n",
    "    if ('batchnorm' in i) and ('weight' in i):\n",
    "        print('Batch shape: {}'.format(newmodel.cnn.state_dict()[i].shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================= conv0 =================\n",
      "Conv shape: torch.Size([32, 32, 3, 3])\n",
      "Batch shape: torch.Size([32])\n",
      "================= conv1 =================\n",
      "Conv shape: torch.Size([64, 32, 3, 3])\n",
      "Batch shape: torch.Size([64])\n",
      "================= conv2 =================\n",
      "Conv shape: torch.Size([128, 64, 3, 3])\n",
      "Batch shape: torch.Size([128])\n",
      "================= conv3 =================\n",
      "Conv shape: torch.Size([128, 128, 3, 3])\n",
      "Batch shape: torch.Size([128])\n",
      "================= conv4 =================\n",
      "Conv shape: torch.Size([256, 128, 3, 3])\n",
      "Batch shape: torch.Size([256])\n",
      "================= conv5 =================\n",
      "Conv shape: torch.Size([256, 256, 3, 3])\n",
      "Batch shape: torch.Size([256])\n",
      "================= conv6 =================\n",
      "Conv shape: torch.Size([256, 256, 2, 2])\n",
      "Batch shape: torch.Size([256])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "newmodel.cnn"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu0): ReLU(inplace=True)\n",
       "  (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (pooling2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu4): ReLU(inplace=True)\n",
       "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu5): ReLU(inplace=True)\n",
       "  (pooling3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (batchnorm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu6): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}